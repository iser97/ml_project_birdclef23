{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Processing\n",
    "- Kmeans clustering\n",
    "   - 各种传统分类算法\n",
    "   - PCA\n",
    "      - SVM（kernel='rbf'）\n",
    "- Meanshift clustering\n",
    "   - SVM（kernel='rbf'）\n",
    "- GMM clustering\n",
    "   - SVM（kernel='rbf'）\n",
    "- Spactral Clustering\n",
    "   - SVM（kernel='rbf'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import os\n",
    "import sys\n",
    "#import tensorflow_hub as hub\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>4.3906</td>\n",
       "      <td>38.2788</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>Rolf A. de By</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.xeno-canto.org/128013</td>\n",
       "      <td>abethr1/XC128013.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://www.xeno-canto.org/363501</td>\n",
       "      <td>abethr1/XC363501.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://www.xeno-canto.org/363502</td>\n",
       "      <td>abethr1/XC363502.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['song']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.xeno-canto.org/363503</td>\n",
       "      <td>abethr1/XC363503.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abethr1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'song']</td>\n",
       "      <td>-2.9524</td>\n",
       "      <td>38.2921</td>\n",
       "      <td>Turdus tephronotus</td>\n",
       "      <td>African Bare-eyed Thrush</td>\n",
       "      <td>James Bradley</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>https://www.xeno-canto.org/363504</td>\n",
       "      <td>abethr1/XC363504.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label secondary_labels              type  latitude  longitude  \\\n",
       "0       abethr1               []          ['song']    4.3906    38.2788   \n",
       "1       abethr1               []          ['call']   -2.9524    38.2921   \n",
       "2       abethr1               []          ['song']   -2.9524    38.2921   \n",
       "3       abethr1               []          ['song']   -2.9524    38.2921   \n",
       "4       abethr1               []  ['call', 'song']   -2.9524    38.2921   \n",
       "\n",
       "      scientific_name               common_name         author  \\\n",
       "0  Turdus tephronotus  African Bare-eyed Thrush  Rolf A. de By   \n",
       "1  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "2  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "3  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "4  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
       "\n",
       "                                             license  rating  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     5.0   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     4.5   \n",
       "\n",
       "                                 url              filename  \n",
       "0  https://www.xeno-canto.org/128013  abethr1/XC128013.ogg  \n",
       "1  https://www.xeno-canto.org/363501  abethr1/XC363501.ogg  \n",
       "2  https://www.xeno-canto.org/363502  abethr1/XC363502.ogg  \n",
       "3  https://www.xeno-canto.org/363503  abethr1/XC363503.ogg  \n",
       "4  https://www.xeno-canto.org/363504  abethr1/XC363504.ogg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "#load data from train_metadata\n",
    "data = pd.read_csv(\"/home/yangya/桌面/project/train_metadata.csv/train_metadata.csv\",engine='python')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载一个音频文件\n",
    "file_prefix = \"/home/yangya/桌面/project/train_audio/\"\n",
    "idx = 5\n",
    "sample = data.iloc[idx]\n",
    "path = file_prefix + sample[\"filename\"]\n",
    "y, sr = librosa.load(path)\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.6870575e+02 -4.6347641e+02 -4.3791876e+02 ... -4.5458032e+02\n",
      "  -4.9969882e+02 -6.2444708e+02]\n",
      " [ 9.0777237e+01  8.6492035e+01  7.7351166e+01 ...  4.1411030e+01\n",
      "   4.3246807e+01  2.6326668e+01]\n",
      " [ 2.6606071e+01  2.2994198e+01  1.6594213e+01 ... -2.5461529e+01\n",
      "  -2.5402603e+01 -1.8658842e+01]\n",
      " ...\n",
      " [-4.9935865e+00 -3.1236262e+00 -4.9313350e+00 ... -1.2057183e+00\n",
      "  -2.5710778e+00 -1.4533738e+00]\n",
      " [-2.1520042e+00 -2.7340665e+00  6.9367188e-01 ...  6.1726303e+00\n",
      "   1.7964215e+00 -7.0786185e+00]\n",
      " [-2.4106234e-01 -2.8649184e-01  4.6178956e+00 ...  6.1697044e+00\n",
      "  -1.9447503e+00 -2.4588399e+00]]\n",
      "(406, 13)\n"
     ]
    }
   ],
   "source": [
    "print(mfccs)\n",
    "print(np.array(mfccs).T.shape)#将计算得到的mfccs保存成转置形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ogg file into mfccs\n",
    "def convert_to_mfccs(data):\n",
    "    mfccs_res = []\n",
    "    file_prefix = \"/home/yangya/桌面/project/train_audio/\"\n",
    "    for i in range(len(data)):\n",
    "        idx =i \n",
    "        sample = data.iloc[idx]\n",
    "        path = file_prefix + sample[\"filename\"]\n",
    "        y, sr = librosa.load(path)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfccs_res.append(mfccs.T)\n",
    "    return mfccs_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mfccs feature \n",
    "train_mfccs = convert_to_mfccs(train_df)\n",
    "test_mfccs= convert_to_mfccs(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delta MFCCs\n",
    "def compute_delta_mfccs(mfccs):\n",
    "    dmfccs = []\n",
    "    for m in mfccs:\n",
    "        tmp = m[1:] - m[0:-1]\n",
    "        dm = np.hstack((m[0:-1], tmp))\n",
    "        dmfccs.append(dm)\n",
    "    return dmfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the compute delta mfccs\n",
    "train_dmfccs = compute_delta_mfccs(train_mfccs)\n",
    "test_dmfccs = compute_delta_mfccs(test_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13552,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangya/anaconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_dmfccs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23898718, 26)\n"
     ]
    }
   ],
   "source": [
    "all_dmfccs = np.vstack(train_dmfccs)\n",
    "print(all_dmfccs.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Use clsteruing method to build the Bag-of-'audio' (clustering method:KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.38003296e+02,  4.62914200e+01, -3.30465698e+00, ...,\n",
       "        -3.51096764e-02, -2.60240138e-01,  3.59313339e-01],\n",
       "       [-3.84653534e+02,  6.24353294e+01, -3.93464279e+00, ...,\n",
       "         1.60134047e-01,  6.94406852e-02,  1.87929615e-01],\n",
       "       [-4.21593597e+02,  3.93832970e+01, -3.12468071e+01, ...,\n",
       "        -4.15435880e-01, -5.12583196e-01, -1.10433251e-01],\n",
       "       ...,\n",
       "       [-3.50888947e+02,  1.01627335e+02, -1.35203018e+01, ...,\n",
       "        -4.14060801e-02,  1.07255816e-01, -3.94188538e-02],\n",
       "       [-4.05173096e+02, -9.22915268e+00, -4.27453957e+01, ...,\n",
       "         1.99975401e-01, -3.31680089e-01,  5.04381321e-02],\n",
       "       [-1.99721375e+02, -1.10095734e+02, -1.40426117e+02, ...,\n",
       "         1.44641730e-03,  6.63463119e-03, -2.33691968e-02]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run k-means to build codebook\n",
    "km = cluster.KMeans(n_clusters=100, random_state=4487)\n",
    "km.fit(all_dmfccs[0::100])  # subsample by 10 to make it faster\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.cluster_centers_.shape[0]\n",
    "    bows = np.zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = np.bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_bow = bow_transform(km, train_dmfccs)\n",
    "test_bow = bow_transform(km,test_dmfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13552, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagnames = data[\"primary_label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of tags into binary class labels\n",
    "def tags2class(tags, tagnames):\n",
    "    b = np.zeros(shape=(len(tags), len(tagnames)))\n",
    "    for i,t in enumerate(tags):\n",
    "        for j,n in enumerate(tagnames):\n",
    "            if n in t:\n",
    "                b[i,j] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes[i,j] = absence/presence of the j-th tag in the i-th sound\n",
    "train_classes_ = tags2class(train_df['primary_label'], tagnames)\n",
    "test_classes_ = tags2class(test_df['primary_label'], tagnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "for i in range(len(train_classes_)):\n",
    "    train_classes.append(np.argmax(train_classes_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = []\n",
    "for j in range(len(test_classes_)):\n",
    "    test_classes.append(np.argmax(test_classes_[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13552,)\n",
      "(3389,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_classes).shape)\n",
    "print(np.array(test_classes).shape)\n",
    "#print(test_classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "train_Xtf = tf_trans.fit_transform(train_bow)\n",
    "test_Xtf  = tf_trans.transform(test_bow)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial TF-IDF with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multinomial NB model\n",
    "def trainMModel(a):\n",
    "    mmodel = naive_bayes.MultinomialNB(alpha = a)\n",
    "    mmodel.fit(train_bow,train_classes)\n",
    "    \n",
    "    testY = test_classes\n",
    "    predY = mmodel.predict(test_bow)\n",
    "    acc = metrics.accuracy_score(testY, predY)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# Grid Search to find the best performance parameter setting (alpha)\n",
    "def GridSearchMModel(start_a, num_a):\n",
    "    best_a = start_a\n",
    "    best_acc = 0.0\n",
    "    for i in range(0, num_a):\n",
    "        a = start_a + (i / (num_a - 1))\n",
    "        tmp_acc = trainMModel(a)\n",
    "        if tmp_acc > best_acc:\n",
    "            best_a = a\n",
    "            best_acc = tmp_acc\n",
    "    return best_a, best_acc\n",
    "\n",
    "best_a, best_acc = GridSearchMModel(0.0, 10001)\n",
    "print(\"Parameter setting with best performance: alpha = {}, accuracy = {}\".format(best_a, best_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinomial TF-IDF with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangya/anaconda3/envs/ML/lib/python3.7/site-packages/sklearn/naive_bayes.py:557: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  % _ALPHA_MIN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter setting with best performance: alpha = 0.046, accuracy = 0.08291531425199174\n"
     ]
    }
   ],
   "source": [
    "# Train Multinomial NB model\n",
    "def trainMModel(a):\n",
    "    mmodel = naive_bayes.MultinomialNB(alpha = a)\n",
    "    mmodel.fit(train_Xtf,train_classes)\n",
    "    \n",
    "    testY = test_classes\n",
    "    predY = mmodel.predict(test_Xtf)\n",
    "    acc = metrics.accuracy_score(testY, predY)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# Grid Search to find the best performance parameter setting (alpha)\n",
    "def GridSearchMModel(start_a, num_a):\n",
    "    best_a = start_a\n",
    "    best_acc = 0.0\n",
    "    for i in range(0, num_a):\n",
    "        a = start_a + (i / (num_a - 1))\n",
    "        tmp_acc = trainMModel(a)\n",
    "        if tmp_acc > best_acc:\n",
    "            best_a = a\n",
    "            best_acc = tmp_acc\n",
    "    return best_a, best_acc\n",
    "\n",
    "best_a, best_acc = GridSearchMModel(0.0, 10001)\n",
    "print(\"Parameter setting with best performance: alpha = {}, accuracy = {}\".format(best_a, best_acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF is better than BOW, so in the next experiments, we use TF-IDF as features to classify species"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suport Vector Machine(SVM) using linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SVM with linear kernel\n",
    "def trainSVM(c):\n",
    "    clf = pipeline.Pipeline([('vect', feature_extraction.text.CountVectorizer()), ('tfidf', feature_extraction.text.TfidfTransformer()), ('clf', svm.SVC(C = c, kernel = 'linear'))])\n",
    "    svm_clf = clf.fit(train_Xtf, train_classes)\n",
    "    svm_predY = svm_clf.predict(test_Xtf)\n",
    "    acc_svm = metrics.accuracy_score(test_classes, svm_predY)\n",
    "    \n",
    "    return acc_svm\n",
    "\n",
    "# Grid Search to find the C with best performance\n",
    "def GridSearchSVM(Cs):\n",
    "    best_c = Cs[0]\n",
    "    best_acc = 0.0\n",
    "    for i in range(len(Cs)):\n",
    "        tmp_acc = trainSVM(Cs[i])\n",
    "        if tmp_acc > best_acc:\n",
    "            best_c = Cs[i]\n",
    "            best_acc = tmp_acc\n",
    "    return best_c, best_acc\n",
    "\n",
    "Cs = np.logspace(-5, 5, 50)\n",
    "best_c, best_acc_svm = GridSearchSVM(Cs)\n",
    "print(\"Parameter setting with best performance: C = {}, accuracy = {}\".format(best_c, best_acc_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) using linear kernel with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([1.00000000e-05, 1.59985872e-05, 2.55954792e-05, 4.09491506e-05,\n",
      "       6.55128557e-05, 1.04811313e-04, 1.67683294e-04, 2.68269580e-04,\n",
      "       4.29193426e-04, 6.86648845e-04, 1.09854114e-03, 1.75751062e-03,\n",
      "       2.81176870e-03, 4.49843267e-03, 7.19685673e-03, 1.15139540e-02,\n",
      "       1.84206997e-02, 2.94705170e-02, 4.71486636e-02, 7.54312006e-02,\n",
      "       1.20679264e-01, 1.93069773e-01, 3.08884360e-01, 4.94171336e-01,\n",
      "       7.90604321e-01, 1.26485522e+00, 2.02358965e+00, 3.23745754e+00,\n",
      "       5.17947468e+00, 8.28642773e+00, 1.32571137e+01, 2.12095089e+01,\n",
      "       3.39322177e+01, 5.42867544e+01, 8.68511374e+01, 1.38949549e+02,\n",
      "       2.22299648e+02, 3.55648031e+02, 5.68986603e+02, 9.10298178e+02,\n",
      "       1.45634848e+03, 2.32995181e+03, 3.72759372e+03, 5.96362332e+03,\n",
      "       9.54095476e+03, 1.52641797e+04, 2.44205309e+04, 3.90693994e+04,\n",
      "       6.25055193e+04, 1.00000000e+05])}\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangya/anaconda3/envs/ML/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv = model_selection.GridSearchCV(svm.SVC(kernel = 'linear'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv.fit(train_Xtf , train_classes);\n",
    "\n",
    "print(\"best params:\", svmcv.best_params_)\n",
    "# predict from the model\n",
    "predY1 = svmcv.best_estimator_.predict(test_Xtf)\n",
    "\n",
    "# calculate accuracy\n",
    "acc1 = metrics.accuracy_score(test_classes, predY1)\n",
    "print(\"test accuracy =\", acc1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Support Vector Machine (SVM) using RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SVM with linear kernel\n",
    "def trainSVMRBF(c):\n",
    "    clf = pipeline.Pipeline([('vect', feature_extraction.text.CountVectorizer()), ('tfidf', feature_extraction.text.TfidfTransformer()), ('clf', svm.SVC(C = c, kernel = 'rbf'))])\n",
    "    svm_clf = clf.fit(train_Xtf, train_classes)\n",
    "    svm_predY = svm_clf.predict(test_Xtf)\n",
    "    acc_svm = metrics.accuracy_score(test_classes, svm_predY)\n",
    "    \n",
    "    return acc_svm\n",
    "\n",
    "# Grid Search to find the C with best performance\n",
    "def GridSearchSVMRBF(Cs):\n",
    "    best_c = Cs[0]\n",
    "    best_acc = 0.0\n",
    "    for i in range(len(Cs)):\n",
    "        tmp_acc = trainSVMRBF(Cs[i])\n",
    "        if tmp_acc > best_acc:\n",
    "            best_c = Cs[i]\n",
    "            best_acc = tmp_acc\n",
    "    return best_c, best_acc\n",
    "\n",
    "Cs = np.logspace(-5, 5, 50)\n",
    "best_c3, best_acc_svm3 = GridSearchSVMRBF(Cs)\n",
    "print(\"Parameter setting with best performance: C = {}, accuracy = {}\".format(best_c3, best_acc_svm3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) using RBF kernel with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv2 = model_selection.GridSearchCV(svm.SVC(kernel = 'rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv2.fit(train_Xtf, train_classes)\n",
    "\n",
    "print(\"best params:\", svmcv2.best_params_)\n",
    "\n",
    "# predict from the model\n",
    "predY2 = svmcv2.best_estimator_.predict(test_Xtf)\n",
    "\n",
    "# calculate accuracy\n",
    "acc2 = metrics.accuracy_score(test_classes, predY2)\n",
    "print(\"test accuracy =\", acc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Gradient Boosting\n",
    "\n",
    "paramsampler= {    \n",
    "    \"colsample_bytree\": stats.uniform(0.7, 0.3),  \n",
    "    \"gamma\":            stats.uniform(0, 0.5),    \n",
    "    \"max_depth\":        stats.randint(2, 6),      \n",
    "    \"subsample\":        stats.uniform(0.6, 0.4),  \n",
    "    \"learning_rate\":    stats.uniform(.001,1),    \n",
    "    \"n_estimators\":     stats.randint(10, 1000),\n",
    "}\n",
    "\n",
    "#X_train, X_test, y_train, y_test = model_selection.train_test_split(trainXtf, trainY, test_size = 0.2, random_state = 0)\n",
    "xclf = xgb.XGBClassifier(objective = \"multi:softmax\", random_state = 4487)\n",
    "xgbcv = model_selection.RandomizedSearchCV(xclf, param_distributions = paramsampler, random_state = 4487, n_iter = 200, cv = 5, verbose = 1, n_jobs = -1)\n",
    "xgbcv.fit(train_Xtf , train_classes)\n",
    "\n",
    "print(\"best params:\", xgbcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predY = xgbcv.best_estimator_.predict(test_Xtf)\n",
    "acc_xgb = metrics.accuracy_score(test_classes, xgb_predY)\n",
    "print(\"Gradient Boosting classifier accuracy: {}\".format(acc_xgb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsampler = {#'max_features': stats.uniform(0,1.0),\n",
    "                 'max_depth':         stats.randint(1,5),\n",
    "                 'min_samples_split': stats.uniform(0,0.5), \n",
    "                 'min_samples_leaf':  stats.uniform(0,0.5),\n",
    "               }\n",
    "\n",
    "rfrcv = model_selection.RandomizedSearchCV(\n",
    "                            ensemble.RandomForestClassifier(n_estimators = 100, random_state = 4487, n_jobs = -1),\n",
    "                            param_distributions = paramsampler, \n",
    "                            random_state = 4487, n_iter = 1000, cv = 5, \n",
    "                            verbose = 1, n_jobs = -1)\n",
    "\n",
    "rfrcv.fit(train_Xtf, train_classes);\n",
    "\n",
    "print(\"best params:\", rfrcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predY = rfrcv.best_estimator_.predict(test_Xtf)\n",
    "acc_rf = metrics.accuracy_score(test_classes, rf_predY)\n",
    "print(\"Random Forest classifier accuracy: {}\".format(acc_rf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LR\n",
    "def trainLR(c):\n",
    "    logreg = pipeline.Pipeline([('vect', feature_extraction.text.CountVectorizer()), ('tfidf', feature_extraction.text.TfidfTransformer()), ('clf', linear_model.LogisticRegression(n_jobs = -1, C = c, solver = 'saga'))])\n",
    "    lr_clf = logreg.fit(train_Xtf, train_classes)\n",
    "    lr_predY = lr_clf.predict(test_Xtf)\n",
    "    acc_lr = metrics.accuracy_score(test_classes, lr_predY)\n",
    "    \n",
    "    return acc_lr\n",
    "\n",
    "# Grid Search to find the C with best performance\n",
    "def GridSearchLR(Cs):\n",
    "    best_c = Cs[0]\n",
    "    best_acc = 0.0\n",
    "    for i in range(len(Cs)):\n",
    "        tmp_acc = trainLR(Cs[i])\n",
    "        if tmp_acc > best_acc:\n",
    "            best_c = Cs[i]\n",
    "            best_acc = tmp_acc\n",
    "    return best_c, best_acc\n",
    "\n",
    "Cs = logspace(-5, 5, 50)\n",
    "best_c_lr, best_acc_lr = GridSearchLR(Cs)\n",
    "print(\"Parameter setting with best performance: C = {}, accuracy = {}\".format(best_c_lr, best_acc_lr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = logspace(-5, 5, 50)\n",
    "\n",
    "# setup the cross-validation object\n",
    "lrcv_clf = pipeline.Pipeline([('vect', feature_extraction.text.CountVectorizer()), ('tfidf', feature_extraction.text.TfidfTransformer()), ('clf', linear_model.LogisticRegressionCV(n_jobs = -1, Cs = Cs, solver = 'saga', max_iter = 10000))])\n",
    "lrcv = lrcv_clf.fit(train_Xtf, train_classes)\n",
    "\n",
    "lr_predY = lrcv.predict(test_Xtf)\n",
    "acc_lrcv = metrics.accuracy_score(test_classes, lr_predY)\n",
    "\n",
    "print(\"Accuracy of LR model with cross-validation: \", acc_lrcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PCA to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=90)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model = decomposition.TruncatedSVD(n_components=90)\n",
    "pca_model.fit(train_Xtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plot the PCA curve\n",
    "def plot_exp_ratio(ratio, title):\n",
    "    explain_fig = plt.figure()\n",
    "    idx = np.where(ratio > 0.95)[0]#[0]\n",
    "    print(\"95% ratio when components are {}\".format(idx))\n",
    "    #plt.title(title)\n",
    "    #plt.plot(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((np.cumsum(pca_model.explained_variance_ratio_)).shape)\n",
    "plot_exp_ratio(np.cumsum(pca_model.explained_variance_ratio_), \n",
    "               \"Explained Variance Ratio(PCA)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert the tran_Xtf and test_xtf to reduced dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_500To285 = decomposition.TruncatedSVD(n_components=76)\n",
    "pca_500To285.fit(train_Xtf)\n",
    "\n",
    "train_Xtfpca = pca_500To285.transform(train_Xtf)\n",
    "test_Xtfpca = pca_500To285.transform(test_Xtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13552, 76)\n",
      "(3389, 76)\n"
     ]
    }
   ],
   "source": [
    "print(train_Xtfpca.shape)\n",
    "print(test_Xtfpca.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SVM (kernel='rbf') to estimate [features dimensionality reduced by PCA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv2 = model_selection.GridSearchCV(svm.SVC(kernel = 'rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv2.fit(train_Xtfpca, train_classes)\n",
    "\n",
    "print(\"best params:\", svmcv2.best_params_)\n",
    "\n",
    "# predict from the model\n",
    "predY2 = svmcv2.best_estimator_.predict(test_Xtfpca)\n",
    "\n",
    "# calculate accuracy\n",
    "acc2 = metrics.accuracy_score(test_classes, predY2)\n",
    "print(\"test accuracy =\", acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Use clsteruing method to build the Bag-of-'audio' (clustering method:Mean-shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.9485876e+02,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [-5.8202631e+02,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "         2.8103402e-02,  2.8199553e-02,  2.9092280e-02],\n",
       "       [-6.5329901e+02, -2.7558545e-02, -3.7574891e-03, ...,\n",
       "        -1.2676661e-02, -2.2265969e-02, -2.8293958e-02],\n",
       "       ...,\n",
       "       [-8.6369983e+02,  7.1583819e-01, -7.5337625e-01, ...,\n",
       "        -8.6526990e-02, -6.8813443e-01, -8.1724358e-01],\n",
       "       [-8.8347571e+02,  7.0363402e-02,  5.7839528e-02, ...,\n",
       "        -2.8870828e+00, -3.5360148e+00, -4.3775770e-01],\n",
       "       [-8.8555505e+02,  5.6913698e-01, -4.2579567e-01, ...,\n",
       "         8.0586481e-01,  2.9934841e-01,  1.6970888e-01]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run k-means to build codebook\n",
    "km = cluster.MeanShift(bandwidth=5, bin_seeding=True, n_jobs=-1)#cluster.KMeans(n_clusters=100, random_state=4487)\n",
    "km.fit(all_dmfccs[0::100])  # subsample by 10 to make it faster\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.cluster_centers_.shape[0]\n",
    "    bows = np.zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = np.bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows\n",
    "\n",
    "trainmeanshift_bow = bow_transform(km, train_dmfccs)\n",
    "testmeanshift_bow = bow_transform(km,test_dmfccs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(kernel='rbf') [features extracted by Meanshift method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "trainmeanshift_Xtf = tf_trans.fit_transform(trainmeanshift_bow )\n",
    "testmeanshift_Xtf  = tf_trans.transform(testmeanshift_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv2 = model_selection.GridSearchCV(svm.SVC(kernel = 'rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv2.fit(trainmeanshift_Xtf , train_classes)\n",
    "\n",
    "print(\"best params:\", svmcv2.best_params_)\n",
    "\n",
    "# predict from the model\n",
    "predY2 = svmcv2.best_estimator_.predict(testmeanshift_Xtf)\n",
    "\n",
    "# calculate accuracy\n",
    "acc2 = metrics.accuracy_score(test_classes, predY2)\n",
    "print(\"test accuracy =\", acc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Use clsteruing method to build the Bag-of-'audio' (clustering method:GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means to build codebook\n",
    "km = mixture.GaussianMixture(n_components=100, covariance_type='full', random_state=4487, n_init=10)\n",
    "km.fit(all_dmfccs[0::100])  # subsample by 10 to make it faster\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.cluster_centers_.shape[0]\n",
    "    bows = np.zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = np.bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows\n",
    "\n",
    "trainGMM_bow = bow_transform(km, train_dmfccs)\n",
    "testGMM_bow = bow_transform(km,test_dmfccs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(kernel='rbf') [features extracted by GMM method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "trainGMM_Xtf = tf_trans.fit_transform(trainGMM_bow )\n",
    "testGMM_Xtf  = tf_trans.transform(testGMM_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv2 = model_selection.GridSearchCV(svm.SVC(kernel = 'rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv2.fit(trainGMM_Xtf , train_classes)\n",
    "\n",
    "print(\"best params:\", svmcv2.best_params_)\n",
    "\n",
    "# predict from the model\n",
    "predY2 = svmcv2.best_estimator_.predict(testGMM_Xtf)\n",
    "\n",
    "# calculate accuracy\n",
    "acc2 = metrics.accuracy_score(test_classes, predY2)\n",
    "print(\"test accuracy =\", acc2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Use clsteruing method to build the Bag-of-'audio' (clustering method:Spectral Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means to build codebook\n",
    "km = luster.SpectralClustering(n_clusters=4100, affinity='rbf', gamma=1.0, assign_labels='discretize', n_jobs=-1)\n",
    "km.fit(all_dmfccs[0::100])  # subsample by 10 to make it faster\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_transform(model, mfccs):\n",
    "    numwords = model.cluster_centers_.shape[0]\n",
    "    bows = np.zeros((len(mfccs), numwords))\n",
    "    for i in range(len(mfccs)):\n",
    "        w = model.predict(mfccs[i])\n",
    "        bw = np.bincount(w, minlength=numwords)\n",
    "        bows[i,:] = bw\n",
    "    return bows\n",
    "\n",
    "trainS_bow = bow_transform(km, train_dmfccs)\n",
    "testS_bow = bow_transform(km,test_dmfccs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM(kernel='rbf') [features extracted by Spectral clustering method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to TF\n",
    "tf_trans = feature_extraction.text.TfidfTransformer(use_idf=True, norm='l1')\n",
    "trainS_Xtf = tf_trans.fit_transform(trainS_bow )\n",
    "testS_Xtf  = tf_trans.transform(testS_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the list of parameters to try\n",
    "paramgrid = {'C': np.logspace(-5, 5, 50)}\n",
    "\n",
    "print(paramgrid)\n",
    "\n",
    "# setup the cross-validation object\n",
    "# pass the SVM object w/ rbf kernel, parameter grid, and number of CV folds\n",
    "svmcv2 = model_selection.GridSearchCV(svm.SVC(kernel = 'rbf'), paramgrid, cv=5, n_jobs=-1, verbose=True)\n",
    "\n",
    "# run cross-validation (train for each split)\n",
    "svmcv2.fit(trainS_Xtf , train_classes)\n",
    "\n",
    "print(\"best params:\", svmcv2.best_params_)\n",
    "\n",
    "# predict from the model\n",
    "predY2 = svmcv2.best_estimator_.predict(testS_Xtf)\n",
    "\n",
    "# calculate accuracy\n",
    "acc2 = metrics.accuracy_score(test_classes, predY2)\n",
    "print(\"test accuracy =\", acc2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
