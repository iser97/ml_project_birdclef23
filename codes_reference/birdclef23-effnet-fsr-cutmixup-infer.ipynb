{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.062037,"end_time":"2022-03-08T03:15:20.082763","exception":false,"start_time":"2022-03-08T03:15:20.020726","status":"completed"},"tags":[]},"source":["# Install Libraries üõ†"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T14:25:13.792408Z","iopub.status.busy":"2023-04-17T14:25:13.791966Z","iopub.status.idle":"2023-04-17T14:25:13.799465Z","shell.execute_reply":"2023-04-17T14:25:13.797196Z","shell.execute_reply.started":"2023-04-17T14:25:13.792369Z"},"trusted":true},"outputs":[],"source":["import sys, os\n","sys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.065343,"end_time":"2022-03-08T03:18:11.885586","exception":false,"start_time":"2022-03-08T03:18:11.820243","status":"completed"},"tags":[]},"source":["# Import Libraries üìö"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-17T14:25:39.483641Z","iopub.status.busy":"2023-04-17T14:25:39.482987Z","iopub.status.idle":"2023-04-17T14:25:51.271808Z","shell.execute_reply":"2023-04-17T14:25:51.270135Z","shell.execute_reply.started":"2023-04-17T14:25:39.483584Z"},"papermill":{"duration":2.632068,"end_time":"2022-03-08T03:18:14.585094","exception":false,"start_time":"2022-03-08T03:18:11.953026","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)\n","import os\n","import pandas as pd\n","import numpy as np\n","import random\n","from glob import glob\n","from tqdm import tqdm\n","tqdm.pandas()\n","import gc\n","import librosa\n","import sklearn\n","import time\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import librosa.display as lid\n","import IPython.display as ipd\n","\n","import tensorflow as tf\n","tf.config.optimizer.set_jit(True) # enable xla for speed up\n","import tensorflow_io as tfio\n","import tensorflow.keras.backend as K\n","\n","import efficientnet.tfkeras as efn"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.066353,"end_time":"2022-03-08T03:18:18.099835","exception":false,"start_time":"2022-03-08T03:18:18.033482","status":"completed"},"tags":[]},"source":["# Configuration ‚öôÔ∏è"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-04-17T14:26:07.114943Z","iopub.status.busy":"2023-04-17T14:26:07.114541Z","iopub.status.idle":"2023-04-17T14:26:07.147507Z","shell.execute_reply":"2023-04-17T14:26:07.146322Z","shell.execute_reply.started":"2023-04-17T14:26:07.114912Z"},"papermill":{"duration":0.156464,"end_time":"2022-03-08T03:18:18.322809","exception":false,"start_time":"2022-03-08T03:18:18.166345","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class CFG:\n","    debug = False\n","    verbose = 0\n","    \n","    device = 'CPU'\n","    seed = 42\n","    \n","    # Input image size and batch size\n","    img_size = [128, 384]\n","    batch_size = 16\n","    infer_bs = 2\n","    tta = 1\n","    drop_remainder = True\n","    \n","    # STFT parameters\n","    duration = 5 # duration for test\n","    train_duration = 10\n","    sample_rate = 32000\n","    downsample = 1\n","    trim = True\n","    audio_len = duration*sample_rate\n","    nfft = 2048\n","    window = 2048\n","    hop_length = train_duration*32000 // (img_size[1] - 1)\n","    fmin = 20\n","    fmax = 16000\n","    normalize = True\n","\n","    # Data Preprocessing Settings\n","    class_names = sorted(os.listdir('/kaggle/input/birdclef-2023/train_audio/'))\n","    num_classes = len(class_names)\n","    class_labels = list(range(num_classes))\n","    label2name = dict(zip(class_labels, class_names))\n","    name2label = {v:k for k,v in label2name.items()}\n","    \n","    target_col = ['target']\n","    tab_cols = ['filename','common_name','rate']"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.070351,"end_time":"2022-03-08T03:18:18.46058","exception":false,"start_time":"2022-03-08T03:18:18.390229","status":"completed"},"tags":[]},"source":["# Reproducibility ‚ôªÔ∏è\n","Sets value for random seed to produce similar result in each run."]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-04-17T14:26:16.435467Z","iopub.status.busy":"2023-04-17T14:26:16.434638Z","iopub.status.idle":"2023-04-17T14:26:16.445323Z","shell.execute_reply":"2023-04-17T14:26:16.444233Z","shell.execute_reply.started":"2023-04-17T14:26:16.435398Z"},"papermill":{"duration":0.153451,"end_time":"2022-03-08T03:18:18.685056","exception":false,"start_time":"2022-03-08T03:18:18.531605","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["seeding done!!!\n"]}],"source":["def seeding(SEED):\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    tf.random.set_seed(SEED)\n","    print('seeding done!!!')\n","seeding(CFG.seed)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.065779,"end_time":"2022-03-08T03:18:18.817867","exception":false,"start_time":"2022-03-08T03:18:18.752088","status":"completed"},"tags":[]},"source":["# Set Up Device  üì±\n","Following codes automatically detects hardware(tpu or tpu-vm or gpu). "]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-04-17T14:26:18.523111Z","iopub.status.busy":"2023-04-17T14:26:18.522597Z","iopub.status.idle":"2023-04-17T14:26:18.533719Z","shell.execute_reply":"2023-04-17T14:26:18.532117Z","shell.execute_reply.started":"2023-04-17T14:26:18.523045Z"},"papermill":{"duration":7.941725,"end_time":"2022-03-08T03:18:26.826553","exception":false,"start_time":"2022-03-08T03:18:18.884828","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_device():\n","    \"Detect and intializes GPU/TPU automatically\"\n","    # Check TPU category\n","    tpu = 'local' if CFG.device=='TPU-VM' else None\n","    try:\n","        # Connect to TPU\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=tpu) \n","        # Set TPU strategy\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","        print(f'> Running on {CFG.device} ', tpu.master(), end=' | ')\n","        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n","        device=CFG.device\n","    except:\n","        # If TPU is not available, detect GPUs\n","        gpus = tf.config.list_logical_devices('GPU')\n","        ngpu = len(gpus)\n","         # Check number of GPUs\n","        if ngpu:\n","            # Set GPU strategy\n","            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n","            # Print GPU details\n","            print(\"> Running on GPU\", end=' | ')\n","            print(\"Num of GPUs: \", ngpu)\n","            device='GPU'\n","        else:\n","            # If no GPUs are available, use CPU\n","            print(\"> Running on CPU\")\n","            strategy = tf.distribute.get_strategy()\n","            device='CPU'\n","    return strategy, device, tpu"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T14:26:20.418367Z","iopub.status.busy":"2023-04-17T14:26:20.417932Z","iopub.status.idle":"2023-04-17T14:26:20.453755Z","shell.execute_reply":"2023-04-17T14:26:20.452420Z","shell.execute_reply.started":"2023-04-17T14:26:20.418332Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> Running on CPU\n"]}],"source":["# Initialize GPU/TPU/TPU-VM\n","strategy, CFG.device, tpu = get_device()\n","CFG.replicas = strategy.num_replicas_in_sync"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Path üìÅ"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T14:26:40.957977Z","iopub.status.busy":"2023-04-17T14:26:40.956844Z","iopub.status.idle":"2023-04-17T14:26:40.963585Z","shell.execute_reply":"2023-04-17T14:26:40.962154Z","shell.execute_reply.started":"2023-04-17T14:26:40.957921Z"},"trusted":true},"outputs":[],"source":["BASE_PATH = '/kaggle/input/birdclef-2023'\n","GCS_PATH = BASE_PATH"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-17T14:26:42.932679Z","iopub.status.busy":"2023-04-17T14:26:42.931197Z","iopub.status.idle":"2023-04-17T14:26:42.986468Z","shell.execute_reply":"2023-04-17T14:26:42.985451Z","shell.execute_reply.started":"2023-04-17T14:26:42.932602Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepath</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/kaggle/input/birdclef-2023/test_soundscapes/s...</td>\n","      <td>soundscape_29201</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            filepath          filename\n","0  /kaggle/input/birdclef-2023/test_soundscapes/s...  soundscape_29201"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_paths = glob('/kaggle/input/birdclef-2023/test_soundscapes/*ogg')\n","test_df = pd.DataFrame(test_paths, columns=['filepath'])\n","test_df['filename'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.ogg',''))\n","test_df.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.077969,"end_time":"2022-03-08T03:18:36.503797","exception":false,"start_time":"2022-03-08T03:18:36.425828","status":"completed"},"tags":[]},"source":["# Data Loader üçö"]},{"cell_type":"code","execution_count":12,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-04-17T14:26:46.223179Z","iopub.status.busy":"2023-04-17T14:26:46.222726Z","iopub.status.idle":"2023-04-17T14:26:46.240842Z","shell.execute_reply":"2023-04-17T14:26:46.239526Z","shell.execute_reply.started":"2023-04-17T14:26:46.223140Z"},"papermill":{"duration":0.251393,"end_time":"2022-03-08T03:18:36.833376","exception":false,"start_time":"2022-03-08T03:18:36.581983","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_audio(filepath, sr=32000, normalize=True):\n","    audio, orig_sr = librosa.load(filepath, sr=None)\n","    if sr!=orig_sr:\n","        audio = librosa.resample(y, orig_sr, sr)\n","    audio = audio.astype('float32').ravel()\n","    audio = tf.convert_to_tensor(audio)\n","    if normalize:\n","        audio = Normalize(audio)\n","    return audio\n","\n","@tf.function(jit_compile=True)\n","def Normalize(data, min_max=True):\n","    # Compute the mean and standard deviation of the data\n","    MEAN = tf.math.reduce_mean(data)\n","    STD = tf.math.reduce_std(data)\n","    # Standardize the data\n","    data = tf.math.divide_no_nan(data - MEAN, STD)\n","    # Normalize to [0, 1]\n","    if min_max:\n","        MIN = tf.math.reduce_min(data)\n","        MAX = tf.math.reduce_max(data)\n","        data = tf.math.divide_no_nan(data - MIN, MAX - MIN)\n","    return data\n","\n","@tf.function(jit_compile=True)\n","def Spec2Img(spec):\n","    spec = tf.tile(spec[..., tf.newaxis], [1, 1, 1, 3])\n","    return spec\n","\n","@tf.function(jit_compile=True)\n","def MakeFrame(audio, duration=5, sr=32000):\n","    frame_length = int(duration * sr)\n","    frame_step = int(duration * sr)\n","    chunks = tf.signal.frame(audio, frame_length, frame_step, pad_end=True)\n","    return chunks\n","\n","def frame_audio(\n","      audio_array: np.ndarray,\n","      window_size_s: float = 5.0,\n","      hop_size_s: float = 5.0,\n","      sample_rate = 32000,\n","      ) -> np.ndarray:\n","    \n","    \"\"\"Helper function for framing audio for inference.\"\"\"\n","    \"\"\" using tf.signal \"\"\"\n","    if window_size_s is None or window_size_s < 0:\n","        return audio_array[np.newaxis, :]\n","    frame_length = int(window_size_s * sample_rate)\n","    hop_length = int(hop_size_s * sample_rate)\n","    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n","    return framed_audio\n","\n","@tf.function(jit_compile=True)\n","def Audio2Spec(audio, spec_shape = CFG.img_size, sr=CFG.sample_rate, \n","                    nfft=CFG.nfft, window=CFG.window, fmin=CFG.fmin, fmax=CFG.fmax, return_img=True):\n","    spec_height = spec_shape[0]\n","    spec_width = spec_shape[1]\n","    hop_length = tf.cast(CFG.hop_length, tf.int32) # sample rate * duration / spec width - 1 == 627\n","    spec = tfio.audio.spectrogram(audio, nfft=nfft, window=window, stride=hop_length)\n","    mel_spec = tfio.audio.melscale(spec, rate=sr, mels=spec_height, fmin=fmin, fmax=fmax)\n","    db_mel_spec = tfio.audio.dbscale(mel_spec, top_db=80)\n","    db_mel_spec = tf.linalg.matrix_transpose(db_mel_spec) # to keep it (batch, mel, time)\n","    return db_mel_spec"]},{"cell_type":"markdown","metadata":{},"source":["# Inference Configs üîß"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T18:41:34.184093Z","iopub.status.busy":"2023-03-13T18:41:34.18277Z","iopub.status.idle":"2023-03-13T18:41:40.123478Z","shell.execute_reply":"2023-03-13T18:41:40.121833Z","shell.execute_reply.started":"2023-03-13T18:41:34.184005Z"},"trusted":true},"outputs":[],"source":["# Directory of checkpoint\n","CKPT_DIR = '/kaggle/input/birdclef23-effnet-fsr-cutmixup-train-ds'\n","# Get file paths of all trained models in the directory\n","CKPT_PATHS = sorted(glob(f'{CKPT_DIR}/*h5'))\n","# Load all the models in memory to speed up\n","CKPTS = [tf.keras.models.load_model(x, compile=False) for x in tqdm(CKPT_PATHS, desc=\"Loading ckpts \")]\n","# Num of ckpt to use\n","NUM_CKPTS = 1\n","\n","# Submit or Interactive mode\n","SUBMIT = pd.read_csv('/kaggle/input/birdclef-2023/sample_submission.csv').shape[0] != 3"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.151237,"end_time":"2022-03-08T03:18:47.959873","exception":false,"start_time":"2022-03-08T03:18:47.808636","status":"completed"},"tags":[]},"source":["# Inference üß™"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T18:41:40.126183Z","iopub.status.busy":"2023-03-13T18:41:40.125621Z","iopub.status.idle":"2023-03-13T18:41:58.022733Z","shell.execute_reply":"2023-03-13T18:41:58.021335Z","shell.execute_reply.started":"2023-03-13T18:41:40.126135Z"},"trusted":true},"outputs":[],"source":["# Start stopwatch\n","tick = time.time()\n","\n","# Initialize empty list to store ids\n","ids = []\n","# Initialize empty array to store predictions\n","preds = np.empty(shape=(0, 264), dtype='float32')\n","\n","# Iterate over each audio file in the test dataset\n","for filepath in tqdm(test_df.filepath.tolist(), 'test '):\n","    # Extract the filename without the extension\n","    filename = filepath.split('/')[-1].replace('.ogg','')\n","    \n","    # Load audio from file and create audio frames, each recording will be a batch input\n","    audio = load_audio(filepath)\n","    chunks = MakeFrame(audio)\n","    \n","#     # If not submitting, only use the first three frames for speed\n","#     if not SUBMIT:\n","#         chunks = chunks[:3]\n","    \n","    # Convert audio frames to spectrograms + rgb image using a vectorized function \n","    specs = Audio2Spec(chunks)\n","    specs = Spec2Img(specs)\n","    \n","    # Predict bird species for all frames in a recording using all trained models\n","    chunk_preds = np.zeros(shape=(len(specs), 264), dtype=np.float32)\n","    for model in CKPTS[:NUM_CKPTS]:\n","        # Get the model's predictions for the current audio frames\n","        rec_preds = model(specs, training=False).numpy()\n","        # Ensemble all prediction with average\n","        chunk_preds += rec_preds/len(CKPTS)\n","    \n","    # Create a ID for each frame in a recording using the filename and frame number\n","    rec_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(chunks))]\n","    \n","    # Concatenate the ids\n","    ids += rec_ids\n","    # Concatenate the predictions\n","    preds = np.concatenate([preds, chunk_preds], axis=0)\n","    \n","# Stop stopwatch\n","tock = time.time()"]},{"cell_type":"markdown","metadata":{},"source":["# Submission üìÆ"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-13T18:41:58.025497Z","iopub.status.busy":"2023-03-13T18:41:58.024981Z","iopub.status.idle":"2023-03-13T18:41:58.165121Z","shell.execute_reply":"2023-03-13T18:41:58.16381Z","shell.execute_reply.started":"2023-03-13T18:41:58.025452Z"},"trusted":true},"outputs":[],"source":["# Submit prediction\n","pred_df = pd.DataFrame(ids, columns=['row_id'])\n","pred_df.loc[:, CFG.class_names] = preds\n","pred_df.to_csv('submission.csv',index=False)\n","pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-13T18:41:58.168544Z","iopub.status.busy":"2023-03-13T18:41:58.166972Z","iopub.status.idle":"2023-03-13T18:41:58.178488Z","shell.execute_reply":"2023-03-13T18:41:58.176828Z","shell.execute_reply.started":"2023-03-13T18:41:58.168487Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not SUBMIT:\n","    pred_labels = pred_df[pred_df.columns[1:]].values.argmax(axis=1)\n","    pred_classes = list(map(lambda x: CFG.label2name[x], pred_labels))\n","    print(pred_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-13T18:41:58.182701Z","iopub.status.busy":"2023-03-13T18:41:58.180391Z","iopub.status.idle":"2023-03-13T18:41:58.193208Z","shell.execute_reply":"2023-03-13T18:41:58.191549Z","shell.execute_reply.started":"2023-03-13T18:41:58.182631Z"},"trusted":true},"outputs":[],"source":["sub_time = (tock-tick)*200 # ~200 recording on the test data\n","sub_time = time.gmtime(sub_time)\n","sub_time = time.strftime(\"%H hr: %M min : %S sec\", sub_time)\n","print(f\">> Time for submission: ~ {sub_time}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
