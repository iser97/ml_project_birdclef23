{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BirdCLEF 2023 🐦\n","> Identify bird calls in soundscapes\n","\n","<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/44224/logos/header.png?t=2023-03-06-18-30-53\">"]},{"cell_type":"markdown","metadata":{},"source":["# Methodology  🎯\n","* This notebook will demonstrate **Bird Call Identification** with `TensorFlow`. Specifically, this notebook shows inference for [BirdCLEF23: Pretraining is All you Need [Train]](https://www.kaggle.com/awsaf49/birdclef23-pretraining-is-all-you-need-infer), where mdoel is initially **pretrained** on BirdCLEF 2021 & 2022 dataset, and then **fine-tuned** in BirdCLEF 2023 dataset.\n","* This notebook differs from previous [notebook](https://www.kaggle.com/awsaf49/birdclef23-effnet-fsr-cutmixup-train/) as unlike previous notebook where model is fed with spectrogram, current notebook feds  raw audio to model.\n","* Raw audio is processed using pre-processing layers from [tensorflow-extra](github.com/awsaf49/tensorflow_extra) library.\n","* This notebook will use `5sec` audio recording as per requirements. But training is done on much more larger size recording. Dynamic shape is utilize to infer on a different resolution.\n","* This notebook will consider one recording as one batch which will speed up the processing."]},{"cell_type":"markdown","metadata":{},"source":["# Notebooks 📓\n","\n","* Pretraining is All you Need\n","    * Train: [BirdCLEF23: Pretraining is All you Need [Train]](https://www.kaggle.com/awsaf49/birdclef23-pretraining-is-all-you-need-train/)\n","    * Infer: [BirdCLEF23: Pretraining is All you Need [Infer]](https://www.kaggle.com/awsaf49/birdclef23-pretraining-is-all-you-need-infer/)\n","    \n","    \n","* EffNet + FSR + CutMixUp\n","    * Train: [BirdCLEF23: EffNet + FSR + CutMixUp [Train]](https://www.kaggle.com/awsaf49/birdclef23-effnet-fsr-cutmixup-train/)\n","    * Infer: [BirdCLEF23: EffNet + FSR + CutMixUp [Infer]](https://www.kaggle.com/awsaf49/birdclef23-effnet-fsr-cutmixup-infer/)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Update 🆕\n","* `v4`:\n","    * BirdCLEF 2020 & Xeno-Canto Extend Dataset added"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.062037,"end_time":"2022-03-08T03:15:20.082763","exception":false,"start_time":"2022-03-08T03:15:20.020726","status":"completed"},"tags":[]},"source":["# Install Libraries 🛠"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:27:29.66564Z","iopub.status.busy":"2023-03-18T17:27:29.665218Z","iopub.status.idle":"2023-03-18T17:27:52.48405Z","shell.execute_reply":"2023-03-18T17:27:52.482583Z","shell.execute_reply.started":"2023-03-18T17:27:29.665601Z"},"trusted":true},"outputs":[],"source":["import sys, os\n","sys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')\n","!pip install -q /kaggle/input/tensorflow-extra-lib-ds/tensorflow_extra-1.0.2-py3-none-any.whl --no-deps"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.065343,"end_time":"2022-03-08T03:18:11.885586","exception":false,"start_time":"2022-03-08T03:18:11.820243","status":"completed"},"tags":[]},"source":["# Import Libraries 📚"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-18T17:27:52.489531Z","iopub.status.busy":"2023-03-18T17:27:52.489131Z","iopub.status.idle":"2023-03-18T17:28:03.569845Z","shell.execute_reply":"2023-03-18T17:28:03.568492Z","shell.execute_reply.started":"2023-03-18T17:27:52.48948Z"},"papermill":{"duration":2.632068,"end_time":"2022-03-08T03:18:14.585094","exception":false,"start_time":"2022-03-08T03:18:11.953026","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)\n","import os\n","import pandas as pd\n","import numpy as np\n","import random\n","from glob import glob\n","from tqdm import tqdm\n","tqdm.pandas()\n","import gc\n","import librosa\n","import sklearn\n","import time\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import librosa.display as lid\n","import IPython.display as ipd\n","\n","import tensorflow as tf\n","tf.config.optimizer.set_jit(True) # enable xla for speed up\n","import tensorflow_io as tfio\n","import tensorflow.keras.backend as K\n","\n","import efficientnet.tfkeras as efn\n","import tensorflow_extra as tfe"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.065649,"end_time":"2022-03-08T03:18:14.717311","exception":false,"start_time":"2022-03-08T03:18:14.651662","status":"completed"},"tags":[]},"source":["## Library Version"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.572786Z","iopub.status.busy":"2023-03-18T17:28:03.57162Z","iopub.status.idle":"2023-03-18T17:28:03.581537Z","shell.execute_reply":"2023-03-18T17:28:03.579986Z","shell.execute_reply.started":"2023-03-18T17:28:03.572726Z"},"papermill":{"duration":0.155095,"end_time":"2022-03-08T03:18:14.939054","exception":false,"start_time":"2022-03-08T03:18:14.783959","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print('np:', np.__version__)\n","print('pd:', pd.__version__)\n","print('sklearn:', sklearn.__version__)\n","print('librosa:', librosa.__version__)\n","print('tf:', tf.__version__)\n","print('tfio:', tfio.__version__)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.066353,"end_time":"2022-03-08T03:18:18.099835","exception":false,"start_time":"2022-03-08T03:18:18.033482","status":"completed"},"tags":[]},"source":["# Configuration ⚙️"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2023-03-18T17:28:03.585434Z","iopub.status.busy":"2023-03-18T17:28:03.584694Z","iopub.status.idle":"2023-03-18T17:28:03.62018Z","shell.execute_reply":"2023-03-18T17:28:03.619085Z","shell.execute_reply.started":"2023-03-18T17:28:03.585395Z"},"papermill":{"duration":0.156464,"end_time":"2022-03-08T03:18:18.322809","exception":false,"start_time":"2022-03-08T03:18:18.166345","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class CFG:\n","    debug = False\n","    verbose = 0\n","    \n","    device = 'CPU'\n","    seed = 42\n","    \n","    # Input image size and batch size\n","    img_size = [128, 384]\n","    batch_size = 16\n","    infer_bs = 2\n","    tta = 1\n","    drop_remainder = True\n","    \n","    # STFT parameters\n","    duration = 5 # duration for test\n","    train_duration = 10\n","    sample_rate = 32000\n","    downsample = 1\n","    audio_len = duration*sample_rate\n","    nfft = 2028\n","    window = 2048\n","    hop_length = train_duration*32000 // (img_size[1] - 1)\n","    fmin = 20\n","    fmax = 16000\n","    normalize = True\n","\n","    # Data Preprocessing Settings\n","    class_names = sorted(os.listdir('/kaggle/input/birdclef-2023/train_audio/'))\n","    num_classes = len(class_names)\n","    class_labels = list(range(num_classes))\n","    label2name = dict(zip(class_labels, class_names))\n","    name2label = {v:k for k,v in label2name.items()}\n","    \n","    target_col = ['target']\n","    tab_cols = ['filename','common_name','rate']"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.070351,"end_time":"2022-03-08T03:18:18.46058","exception":false,"start_time":"2022-03-08T03:18:18.390229","status":"completed"},"tags":[]},"source":["# Reproducibility ♻️\n","Sets value for random seed to produce similar result in each run."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:28:03.621779Z","iopub.status.busy":"2023-03-18T17:28:03.621449Z","iopub.status.idle":"2023-03-18T17:28:03.626466Z","shell.execute_reply":"2023-03-18T17:28:03.625564Z","shell.execute_reply.started":"2023-03-18T17:28:03.621748Z"},"papermill":{"duration":0.153451,"end_time":"2022-03-08T03:18:18.685056","exception":false,"start_time":"2022-03-08T03:18:18.531605","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["tf.keras.utils.set_random_seed(CFG.seed)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.065779,"end_time":"2022-03-08T03:18:18.817867","exception":false,"start_time":"2022-03-08T03:18:18.752088","status":"completed"},"tags":[]},"source":["# Set Up Device  📱\n","Following codes automatically detects hardware(tpu or tpu-vm or gpu). "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:28:03.628881Z","iopub.status.busy":"2023-03-18T17:28:03.627736Z","iopub.status.idle":"2023-03-18T17:28:03.63909Z","shell.execute_reply":"2023-03-18T17:28:03.637962Z","shell.execute_reply.started":"2023-03-18T17:28:03.62884Z"},"papermill":{"duration":7.941725,"end_time":"2022-03-08T03:18:26.826553","exception":false,"start_time":"2022-03-08T03:18:18.884828","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_device():\n","    \"Detect and intializes GPU/TPU automatically\"\n","    # Check TPU category\n","    tpu = 'local' if CFG.device=='TPU-VM' else None\n","    try:\n","        # Connect to TPU\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=tpu) \n","        # Set TPU strategy\n","        strategy = tf.distribute.TPUStrategy(tpu)\n","        print(f'> Running on {CFG.device} ', tpu.master(), end=' | ')\n","        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n","        device=CFG.device\n","    except:\n","        # If TPU is not available, detect GPUs\n","        gpus = tf.config.list_logical_devices('GPU')\n","        ngpu = len(gpus)\n","         # Check number of GPUs\n","        if ngpu:\n","            # Set GPU strategy\n","            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n","            # Print GPU details\n","            print(\"> Running on GPU\", end=' | ')\n","            print(\"Num of GPUs: \", ngpu)\n","            device='GPU'\n","        else:\n","            # If no GPUs are available, use CPU\n","            print(\"> Running on CPU\")\n","            strategy = tf.distribute.get_strategy()\n","            device='CPU'\n","    return strategy, device, tpu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.641055Z","iopub.status.busy":"2023-03-18T17:28:03.640601Z","iopub.status.idle":"2023-03-18T17:28:03.675269Z","shell.execute_reply":"2023-03-18T17:28:03.673863Z","shell.execute_reply.started":"2023-03-18T17:28:03.641008Z"},"trusted":true},"outputs":[],"source":["# Initialize GPU/TPU/TPU-VM\n","strategy, CFG.device, tpu = get_device()\n","CFG.replicas = strategy.num_replicas_in_sync"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Path 📁"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.677278Z","iopub.status.busy":"2023-03-18T17:28:03.676934Z","iopub.status.idle":"2023-03-18T17:28:03.683029Z","shell.execute_reply":"2023-03-18T17:28:03.681577Z","shell.execute_reply.started":"2023-03-18T17:28:03.677246Z"},"trusted":true},"outputs":[],"source":["BASE_PATH = '/kaggle/input/birdclef-2023'\n","GCS_PATH = BASE_PATH"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.067107,"end_time":"2022-03-08T03:18:26.962626","exception":false,"start_time":"2022-03-08T03:18:26.895519","status":"completed"},"tags":[]},"source":["# Meta Data 📖\n","* **test_soundscapes/** - directory contains $~200$ recordings to be used for scoring when a notebook is submitted. Without submission only $1$ recording is accessible.  All recordings are $10$ minutes long and in `.ogg` audio format.\n","* **sample_submission.csv** - is the valid sample submission.\n","    * `row_id`: A slug of [soundscape_id]_[end_time] for the prediction.\n","    * `[bird_id]`: There are $264$ bird ID columns. The probability of the presence of each bird for each row needs to be predicted."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.685703Z","iopub.status.busy":"2023-03-18T17:28:03.68495Z","iopub.status.idle":"2023-03-18T17:28:03.71941Z","shell.execute_reply":"2023-03-18T17:28:03.718561Z","shell.execute_reply.started":"2023-03-18T17:28:03.685653Z"},"trusted":true},"outputs":[],"source":["test_paths = glob('/kaggle/input/birdclef-2023/test_soundscapes/*ogg')\n","test_df = pd.DataFrame(test_paths, columns=['filepath'])\n","test_df['filename'] = test_df.filepath.map(lambda x: x.split('/')[-1].replace('.ogg',''))\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.72299Z","iopub.status.busy":"2023-03-18T17:28:03.722421Z","iopub.status.idle":"2023-03-18T17:28:03.730038Z","shell.execute_reply":"2023-03-18T17:28:03.728768Z","shell.execute_reply.started":"2023-03-18T17:28:03.722955Z"},"papermill":{"duration":0.244976,"end_time":"2022-03-08T03:18:33.994955","exception":false,"start_time":"2022-03-08T03:18:33.749979","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["tf.io.gfile.exists(test_df.filepath.iloc[0])"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.077969,"end_time":"2022-03-08T03:18:36.503797","exception":false,"start_time":"2022-03-08T03:18:36.425828","status":"completed"},"tags":[]},"source":["# Data Loader 🍚"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:28:03.732289Z","iopub.status.busy":"2023-03-18T17:28:03.731759Z","iopub.status.idle":"2023-03-18T17:28:03.742874Z","shell.execute_reply":"2023-03-18T17:28:03.741725Z","shell.execute_reply.started":"2023-03-18T17:28:03.732242Z"},"papermill":{"duration":0.251393,"end_time":"2022-03-08T03:18:36.833376","exception":false,"start_time":"2022-03-08T03:18:36.581983","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_audio(filepath, sr=32000, normalize=True):\n","    audio, orig_sr = librosa.load(filepath, sr=None)\n","    if sr!=orig_sr:\n","        audio = librosa.resample(y, orig_sr, sr)\n","    audio = audio.astype('float32').ravel()\n","    audio = tf.convert_to_tensor(audio)\n","    return audio\n","\n","@tf.function(jit_compile=True)\n","def MakeFrame(audio, duration=5, sr=32000):\n","    frame_length = int(duration * sr)\n","    frame_step = int(duration * sr)\n","    chunks = tf.signal.frame(audio, frame_length, frame_step, pad_end=True)\n","    return chunks\n","\n","librosa.util.frame()\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.091062,"end_time":"2022-03-08T03:18:37.019504","exception":false,"start_time":"2022-03-08T03:18:36.928442","status":"completed"},"tags":[]},"source":["# EDA 🎨"]},{"cell_type":"markdown","metadata":{},"source":["## Utility"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:28:03.745633Z","iopub.status.busy":"2023-03-18T17:28:03.745105Z","iopub.status.idle":"2023-03-18T17:28:03.757021Z","shell.execute_reply":"2023-03-18T17:28:03.755949Z","shell.execute_reply.started":"2023-03-18T17:28:03.745583Z"},"trusted":true},"outputs":[],"source":["def display_audio(row):\n","    # Caption for viz\n","    caption = f'Id: {row.filename}'\n","    # Read audio file\n","    audio = load_audio(row.filepath)\n","    # Keep fixed length audio\n","    audio = audio[:CFG.audio_len]\n","    # Display audio\n","    print(\"# Audio:\")\n","    display(ipd.Audio(audio.numpy(), rate=CFG.sample_rate))\n","    print('# Visualization:')\n","    plt.figure(figsize=(12, 3))\n","    plt.title(caption)\n","    # Waveplot\n","    lid.waveshow(audio.numpy(),\n","                 sr=CFG.sample_rate,)\n","                 \n","    plt.xlabel('');\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Check"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:28:03.759131Z","iopub.status.busy":"2023-03-18T17:28:03.75872Z","iopub.status.idle":"2023-03-18T17:28:16.816782Z","shell.execute_reply":"2023-03-18T17:28:16.815427Z","shell.execute_reply.started":"2023-03-18T17:28:03.759085Z"},"trusted":true},"outputs":[],"source":["display_audio(test_df.iloc[0])"]},{"cell_type":"markdown","metadata":{},"source":["# Inference Configs 🔧"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:32:27.80521Z","iopub.status.busy":"2023-03-18T17:32:27.80418Z","iopub.status.idle":"2023-03-18T17:32:32.239775Z","shell.execute_reply":"2023-03-18T17:32:32.238583Z","shell.execute_reply.started":"2023-03-18T17:32:27.805163Z"},"trusted":true},"outputs":[],"source":["# Directory of checkpoint\n","CKPT_DIR = '/kaggle/input/birdclef23-pretraining-is-all-you-need-train-ds'\n","# Get file paths of all trained models in the directory\n","CKPT_PATHS = sorted([x for x in glob(f'{CKPT_DIR}/fold-*h5')])\n","print(\"Checkpoints: \", CKPT_PATHS)\n","# Load all the models in memory to speed up\n","CKPTS = [tf.keras.models.load_model(x, compile=False) for x in tqdm(CKPT_PATHS, desc=\"Loading ckpts \")]\n","# Num of ckpt to use\n","NUM_CKPTS = 1\n","\n","# Submit or Interactive mode\n","SUBMIT = pd.read_csv('/kaggle/input/birdclef-2023/sample_submission.csv').shape[0] != 3"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.151237,"end_time":"2022-03-08T03:18:47.959873","exception":false,"start_time":"2022-03-08T03:18:47.808636","status":"completed"},"tags":[]},"source":["# Inference 🧪"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:32:35.136027Z","iopub.status.busy":"2023-03-18T17:32:35.135629Z","iopub.status.idle":"2023-03-18T17:33:05.851578Z","shell.execute_reply":"2023-03-18T17:33:05.850703Z","shell.execute_reply.started":"2023-03-18T17:32:35.135993Z"},"trusted":true},"outputs":[],"source":["# Start stopwatch\n","tick = time.time()\n","\n","# Initialize empty list to store ids\n","ids = []\n","# Initialize empty array to store predictions\n","preds = np.empty(shape=(0, 264), dtype='float32')\n","\n","# Iterate over each audio file in the test dataset\n","for filepath in tqdm(test_df.filepath.tolist(), 'test '):\n","    # Extract the filename without the extension\n","    filename = filepath.split('/')[-1].replace('.ogg','')\n","    \n","    # Load audio from file and create audio frames, each recording will be a batch input\n","    audio = load_audio(filepath)\n","    chunks = MakeFrame(audio)\n","    \n","    # Predict bird species for all frames in a recording using all trained models\n","    chunk_preds = np.zeros(shape=(len(chunks), 264), dtype=np.float32)\n","    for model in CKPTS[:NUM_CKPTS]:\n","        # Get the model's predictions for the current audio frames\n","        rec_preds = model(chunks, training=False).numpy()\n","        # Ensemble all prediction with average\n","        chunk_preds += rec_preds/len(CKPTS)\n","    \n","    # Create a ID for each frame in a recording using the filename and frame number\n","    rec_ids = [f'{filename}_{(frame_id+1)*5}' for frame_id in range(len(chunks))]\n","    \n","    # Concatenate the ids\n","    ids += rec_ids\n","    # Concatenate the predictions\n","    preds = np.concatenate([preds, chunk_preds], axis=0)\n","    \n","# Stop stopwatch\n","tock = time.time()"]},{"cell_type":"markdown","metadata":{},"source":["# Submission 📮"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-18T17:29:00.096436Z","iopub.status.busy":"2023-03-18T17:29:00.095867Z","iopub.status.idle":"2023-03-18T17:29:00.227741Z","shell.execute_reply":"2023-03-18T17:29:00.226486Z","shell.execute_reply.started":"2023-03-18T17:29:00.096387Z"},"trusted":true},"outputs":[],"source":["# Submit prediction\n","pred_df = pd.DataFrame(ids, columns=['row_id'])\n","pred_df.loc[:, CFG.class_names] = preds\n","pred_df.to_csv('submission.csv',index=False)\n","pred_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Check Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:29:00.230248Z","iopub.status.busy":"2023-03-18T17:29:00.229483Z","iopub.status.idle":"2023-03-18T17:29:00.240032Z","shell.execute_reply":"2023-03-18T17:29:00.238972Z","shell.execute_reply.started":"2023-03-18T17:29:00.230202Z"},"trusted":true},"outputs":[],"source":["if not SUBMIT:\n","    pred_labels = pred_df[pred_df.columns[1:]].values.argmax(axis=1)\n","    pred_classes = list(map(lambda x: CFG.label2name[x], pred_labels))\n","    print(pred_classes)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission Time ⏰\n","Estimated time to complete the submission.\n","> **Note**: There are nearly ~$200$ recordings on the test data."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-03-18T17:29:00.242156Z","iopub.status.busy":"2023-03-18T17:29:00.241622Z","iopub.status.idle":"2023-03-18T17:29:00.250327Z","shell.execute_reply":"2023-03-18T17:29:00.249037Z","shell.execute_reply.started":"2023-03-18T17:29:00.242121Z"},"trusted":true},"outputs":[],"source":["sub_time = (tock-tick)*200 # ~200 recording on the test data\n","sub_time = time.gmtime(sub_time)\n","sub_time = time.strftime(\"%H hr: %M min : %S sec\", sub_time)\n","print(f\">> Time for submission: ~ {sub_time}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
